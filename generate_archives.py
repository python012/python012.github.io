"""
ç”Ÿæˆæ–‡ç« åˆ—è¡¨å’Œå½’æ¡£é¡µé¢
"""

import os
from pathlib import Path
import re

def parse_frontmatter(md_file):
    """è§£æ Markdown æ–‡ä»¶çš„ frontmatter"""
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– frontmatter
    match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
    if not match:
        return None
    
    frontmatter = {}
    current_key = None
    
    for line in match.group(1).split('\n'):
        line = line.rstrip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åˆ—è¡¨é¡¹
        if line.startswith('  - '):
            if current_key == 'tags':
                tag = line.strip('  -').strip()
                if tag:
                    frontmatter['tags'].append(tag)
        elif ':' in line:
            key, value = line.split(':', 1)
            key = key.strip()
            value = value.strip()
            
            if key == 'tags':
                frontmatter['tags'] = []
                current_key = 'tags'
            elif key == 'title':
                # ç§»é™¤å¼•å·
                value = value.strip('"').strip("'")
                frontmatter[key] = value
                current_key = key
            else:
                frontmatter[key] = value
                current_key = key
    
    return frontmatter

def collect_articles(base_dir):
    """æ”¶é›†æ‰€æœ‰æ–‡ç« ä¿¡æ¯"""
    articles = []
    base_path = Path(base_dir)
    
    for year_dir in ['2016', '2017', '2018', '2025']:
        year_path = base_path / year_dir
        if not year_path.exists():
            continue
        
        for md_file in year_path.rglob('*.md'):
            try:
                frontmatter = parse_frontmatter(md_file)
                if frontmatter and 'title' in frontmatter:
                    # æ„å»ºç›¸å¯¹è·¯å¾„
                    rel_path = md_file.relative_to(base_path)
                    url_path = '/' + str(rel_path).replace('\\', '/').replace('.md', '')
                    
                    articles.append({
                        'title': frontmatter.get('title', ''),
                        'date': frontmatter.get('date', ''),
                        'tags': frontmatter.get('tags', []),
                        'path': url_path,
                        'year': year_dir,
                        'file': md_file
                    })
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶å‡ºé”™ {md_file}: {e}")
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
    articles.sort(key=lambda x: x['date'], reverse=True)
    return articles

def generate_archives_page(articles, output_file):
    """ç”Ÿæˆå½’æ¡£é¡µé¢"""
    content = """# æ–‡ç« å½’æ¡£

## ğŸ“š å…¨éƒ¨æ–‡ç« 

"""
    
    # æŒ‰å¹´ä»½åˆ†ç»„
    articles_by_year = {}
    for article in articles:
        year = article['year']
        if year not in articles_by_year:
            articles_by_year[year] = []
        articles_by_year[year].append(article)
    
    # ç”Ÿæˆå†…å®¹
    for year in sorted(articles_by_year.keys(), reverse=True):
        content += f"\n### {year}å¹´\n\n"
        for article in articles_by_year[year]:
            date = article['date']
            title = article['title']
            path = article['path']
            content += f"- **{date}** - [{title}]({path})\n"
    
    content += f"\n\n---\n\n> å…± {len(articles)} ç¯‡æ–‡ç« \n"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ“ å·²ç”Ÿæˆå½’æ¡£é¡µé¢: {output_file}")

def generate_tags_page(articles, output_file):
    """ç”Ÿæˆæ ‡ç­¾é¡µé¢"""
    # æ”¶é›†æ‰€æœ‰æ ‡ç­¾
    tags_dict = {}
    for article in articles:
        for tag in article['tags']:
            if tag not in tags_dict:
                tags_dict[tag] = []
            tags_dict[tag].append(article)
    
    content = """# æ ‡ç­¾

## ğŸ·ï¸ æ‰€æœ‰æ ‡ç­¾

"""
    
    # æŒ‰æ ‡ç­¾å­—æ¯é¡ºåºæ’åº
    for tag in sorted(tags_dict.keys()):
        articles_with_tag = tags_dict[tag]
        # åˆ›å»ºé”šç‚¹ IDï¼ˆè½¬å°å†™ï¼Œå»é™¤ç©ºæ ¼ï¼‰
        tag_id = tag.lower().replace(' ', '-')
        content += f"\n### <span id=\"{tag_id}\">{tag}</span> ({len(articles_with_tag)})\n\n"
        for article in articles_with_tag:
            content += f"- [{article['title']}]({article['path']}) - {article['date']}\n"
    
    content += f"\n\n---\n\n> å…± {len(tags_dict)} ä¸ªæ ‡ç­¾\n"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ“ å·²ç”Ÿæˆæ ‡ç­¾é¡µé¢: {output_file}")

def generate_index_recent_posts(articles, output_file):
    """æ›´æ–°é¦–é¡µçš„æœ€è¿‘æ–‡ç« """
    # è¯»å–ç°æœ‰é¦–é¡µ
    with open(output_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ç”Ÿæˆæœ€è¿‘æ–‡ç« åˆ—è¡¨ï¼ˆå‰10ç¯‡ï¼‰
    recent_posts = "\n## ğŸ“ æœ€è¿‘æ›´æ–°\n\n"
    for article in articles[:10]:
        recent_posts += f"- **{article['date']}** - [{article['title']}]({article['path']})\n"
    
    recent_posts += f"\n[æŸ¥çœ‹å…¨éƒ¨ {len(articles)} ç¯‡æ–‡ç«  â†’](/archives)\n"
    
    # æ›¿æ¢å†…å®¹
    new_content = re.sub(
        r'## æœ€è¿‘æ›´æ–°.*?(?=##|$)', 
        recent_posts + '\n',
        content,
        flags=re.DOTALL
    )
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(new_content)
    
    print(f"âœ“ å·²æ›´æ–°é¦–é¡µ: {output_file}")

def main():
    print("=" * 60)
    print("ç”Ÿæˆæ–‡ç« åˆ—è¡¨å’Œå½’æ¡£é¡µé¢")
    print("=" * 60)
    print()
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ”¶é›†æ–‡ç« 
    print("æ­£åœ¨æ”¶é›†æ–‡ç« ä¿¡æ¯...")
    articles = collect_articles(base_dir)
    print(f"æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
    print()
    
    # ç”Ÿæˆå½’æ¡£é¡µé¢
    generate_archives_page(articles, os.path.join(base_dir, 'archives.md'))
    
    # ç”Ÿæˆæ ‡ç­¾é¡µé¢
    generate_tags_page(articles, os.path.join(base_dir, 'tags.md'))
    
    # æ›´æ–°é¦–é¡µ
    generate_index_recent_posts(articles, os.path.join(base_dir, 'index.md'))
    
    print()
    print("=" * 60)
    print("å®Œæˆï¼")
    print("=" * 60)

if __name__ == '__main__':
    main()
